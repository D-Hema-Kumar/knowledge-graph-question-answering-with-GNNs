{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from loguru import logger\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from core.LLM.LLMEncoder import LLMEncoder\n",
    "from core.ToTorch.DataBuilder import QADataBuilder, QAMaskBuilder\n",
    "from config.config import (\n",
    "    TRIPLES_PATH,\n",
    "    ENTITIES_LABELS_PATH,\n",
    "    PROPERTIES_LABELS_PATH,\n",
    "    GRAPH_EMBEDDINGS_PATH,\n",
    "    QUESTIONS_ANSWERS_PATH,\n",
    "    QUESTIONS_EMBEDDINGS_PATH,\n",
    "    QUESTIONS_CONCEPTS_ANSWERS_PATH,\n",
    "    GRAPH_EMBEDDINGS_WITH_COMMENT_PATH,\n",
    "\n",
    "\n",
    "    TRIPLES_PATH_OLD,\n",
    "    ENTITIES_LABELS_PATH_OLD,\n",
    "    PROPERTIES_LABELS_PATH_OLD,\n",
    "    GRAPH_EMBEDDINGS_PATH_OLD,\n",
    "    QUESTIONS_CONCEPTS_ANSWERS_PATH,\n",
    "    GRAPH_EMBEDDINGS_PATH_OLD\n",
    ")\n",
    "\n",
    "from core.NeuralNet.GNN import GCN\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "encoder_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "NUM_EPOCHS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "## CREATE DATA\n",
    "logger.info(\"Creating Data object\")\n",
    "\n",
    "qa_data_builder = QADataBuilder(\n",
    "    triples_path=TRIPLES_PATH,\n",
    "    entities_labels_path=ENTITIES_LABELS_PATH,\n",
    "    properties_labels_path=PROPERTIES_LABELS_PATH,\n",
    "    embeddings_path=GRAPH_EMBEDDINGS_PATH,\n",
    "    questions_answers_path=QUESTIONS_ANSWERS_PATH,\n",
    "    questions_embeddings_path=QUESTIONS_EMBEDDINGS_PATH,\n",
    ")\n",
    "\n",
    "x = qa_data_builder.get_x()\n",
    "train_mask, test_mask, val_mask = qa_data_builder.get_questions_masks()\n",
    "NUM_EPOCHS_PER_QUESTION = int(NUM_EPOCHS / sum(train_mask))\n",
    "\n",
    "## TRAIN MLP\n",
    "logger.info(\"Training MLP\")\n",
    "model = MLP(\n",
    "    num_node_features=(2 * x.shape[1]), dim_hidden_layer=16, num_classes=2\n",
    ")  # we multiply x.shape by two so as to account for question embedding\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()\n",
    "\n",
    "for q_index, question_embedding in enumerate(\n",
    "    qa_data_builder.questions_embeddings_masked(train_mask)\n",
    "):  # call the questions_iterator from the instance\n",
    "    question, q_embedding = question_embedding\n",
    "    q_x = qa_data_builder.get_x(\n",
    "        to_concat=q_embedding\n",
    "    )  # add question embedding to node features embedding\n",
    "    q_y = qa_data_builder.get_y(question=question)\n",
    "    data = Data(x=q_x, y=q_y)\n",
    "    if not data.validate():\n",
    "        logger.error(f\"Data object is not valid for question {question}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS_PER_QUESTION):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y, weight = torch.tensor([0.000001, 1-0.000001]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    logger.debug(\n",
    "        f\"Total Question: {(q_index + 1)}, Total Epochs: {NUM_EPOCHS_PER_QUESTION * (q_index + 1):3d}, Loss: {loss:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_qa_model(model=model, qa_data_builder=qa_data_builder, mask=train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_answer(model, data):\n",
    "    \"\"\"\n",
    "    Returns the predicted answer and node index.\n",
    "    \"\"\"\n",
    "    return model(data).max(dim=1)[0].argmax().item()\n",
    "\n",
    "def evaluate_qa_model(model, qa_data_builder, mask):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    for q_index, question_embedding in enumerate(\n",
    "        qa_data_builder.questions_embeddings_masked(mask)\n",
    "    ):\n",
    "        question, q_embedding = question_embedding\n",
    "        x_q = qa_data_builder.get_x(\n",
    "            to_concat=q_embedding\n",
    "        )  # adding the question embedding to the node embeddings\n",
    "        y_q = qa_data_builder.get_y(question=question)\n",
    "        data = Data(x=x_q, edge_index=qa_data_builder.get_edge_index(), y=y_q)\n",
    "        pred_node_idx = _predict_answer(model, data)\n",
    "        actual_node_idx = qa_data_builder.get_node_index_for_question_answer(question)\n",
    "        if pred_node_idx == actual_node_idx:\n",
    "            logger.debug(f\"Correctly predicted answer to question {question}.\")\n",
    "            correct_predictions += 1\n",
    "        elif pred_node_idx != torch.tensor(0):\n",
    "            logger.debug(\n",
    "                f\"Question: {question}. Predicted answer = {qa_data_builder.index_to_entity[pred_node_idx]}, Actual answer: {qa_data_builder.index_to_entity[actual_node_idx]}\"\n",
    "            )\n",
    "        else:\n",
    "            logger.debug(f\"Could not predict any answer\")\n",
    "    return correct_predictions / (q_index + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(6,5)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 4, 0,5],\n",
    "                           [1, 2, 3, 4, 0, 3,1]], dtype=torch.long)\n",
    "edge_type = torch.tensor([0, 1, 0, 2, 1, 3,0], dtype=torch.long)\n",
    "data = Data(edge_index=edge_index, edge_type=edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 0, 5],\n",
       "        [1, 2, 3, 4, 0, 3, 1]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 2, 1, 3, 0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_uri = [\"uri_1\",\"uri_2\"]\n",
    "uri_to_index = {\"uri_1\":8,\"uri_2\":22,\"uri_3\":38}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 22]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_nodes = [uri_to_index[uri] for uri in question_uri]\n",
    "question_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 3])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.isin(data.edge_index[0], torch.tensor([0]))\n",
    "ohp_n = torch.unique(data.edge_index[1, mask])\n",
    "torch.unique(torch.cat((ohp_n,torch.tensor([0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_mask:  tensor([ True, False, False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "question_subgraph_concepts = torch.tensor([0, 1, 2, 3, 4])\n",
    "question_mask = torch.zeros_like(question_subgraph_concepts, dtype=torch.bool)\n",
    "question_training_mask = torch.zeros_like(question_subgraph_concepts, dtype=torch.bool)\n",
    "answer_mask = torch.zeros_like(question_subgraph_concepts, dtype=torch.bool)\n",
    "\n",
    "# q_mask\n",
    "question_mask = question_mask | torch.isin(question_subgraph_concepts , torch.tensor([0,4]) )\n",
    "print (\"question_mask: \",question_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question node\n",
    "q_nodes =  0 # list of entities identified in the question\n",
    "a_nodes = 4\n",
    "\n",
    "# 1 hop neighbors for q_node\n",
    "one_hop_neighbors = data.edge_index[1, data.edge_index[0] == q_node]\n",
    "\n",
    "# add the q_node to one hop neighbors\n",
    "one_hop_neighbors_with_q_node = torch.cat((one_hop_neighbors,torch.tensor(q_node).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hop_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subgraph_mask -- To filter the edge_index and edge type attributes of data class for the question\n",
    "#concepts \n",
    "# Below masks to be used by the list concepts.\n",
    "#answer_mask -- \n",
    "#question_mask --\n",
    "#question_train_mask -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_subgraph_concepts:  tensor([0, 1, 2, 3, 4])\n",
      "question_mask:  tensor([ True, False, False, False, False])\n",
      "answer_mask:  tensor([False, False, False, False,  True])\n",
      "question_training_mask:  tensor([False,  True,  True,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "subgraph_mask = torch.zeros_like(data.edge_index[0], dtype=torch.bool)\n",
    "for node in one_hop_neighbors_with_q_node:\n",
    "    subgraph_mask = subgraph_mask | (data.edge_index[0]==node)\n",
    "\n",
    "question_subgraph_concepts = torch.unique(data.edge_index[:,subgraph_mask]) # all concepts in the subgraph\n",
    "print(\"question_subgraph_concepts: \", question_subgraph_concepts)\n",
    "\n",
    "# initialize masks: \n",
    "question_mask = torch.zeros_like(question_subgraph_concepts, dtype=torch.bool)\n",
    "question_training_mask = torch.zeros_like(question_subgraph_concepts, dtype=torch.bool)\n",
    "answer_mask = torch.zeros_like(question_subgraph_concepts, dtype=torch.bool)\n",
    "\n",
    "# q_mask\n",
    "question_mask = question_mask | (question_subgraph_concepts == q_nodes )\n",
    "print (\"question_mask: \",question_mask)\n",
    "\n",
    "#check if answer is present in the question_subgraph_concepts\n",
    "\n",
    "answer_mask = answer_mask | (question_subgraph_concepts == a_nodes )\n",
    "print (\"answer_mask: \",answer_mask)\n",
    "\n",
    "# randomly sample n nodes including the answer node and exclude q_node from the question_subgraph_concepts\n",
    "\n",
    "# Exclude question_mask and answer_mask items\n",
    "valid_indices = torch.where(~question_mask & ~answer_mask)[0]\n",
    "n=3\n",
    "if n < len(valid_indices):\n",
    "    random_indices  = random.sample(valid_indices.tolist(), n)\n",
    "    question_training_mask[random_indices] = True\n",
    "    question_training_mask = question_training_mask | answer_mask\n",
    "else:\n",
    "    question_training_mask[~question_mask] = True\n",
    "print (\"question_training_mask: \",question_training_mask)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 0, 5],\n",
       "        [1, 2, 3, 4, 0, 3, 1]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 3, 0],\n",
       "        [1, 2, 4, 3]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index[:,subgraph_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_subgraph_concepts[question_training_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume 100 nodes of feature dim 5\n",
    "data.x = torch.randn(100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the x mask and y label for that masked nodes. the dimension will be same as number of nodes in the entire graph?\n",
    "\n",
    "q_x_mask = torch.full((data.x.size()[0],),False, dtype=torch.bool)\n",
    "q_y_label = torch.zeros((data.x.size()[0],), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_x_mask[question_subgraph_concepts[question_training_mask]] = True\n",
    "q_x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_y_label[question_subgraph_concepts[answer_mask]] = 1\n",
    "q_y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_y_label[q_x_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. create a basic data object\\n2. for each question+embedding+question_node+answer_node:\\n\\ta. get all the masks related to the question. # potentially using a method of the QA dataset class\\n\\tb. construct the  q_x = qa_data_builder.get_x(to_concat=q_embedding)  # add question embedding to node features embedding\\n\\tc. build the Data object for the question with filtered edge types and edge index, data = Data(x=q_x, y=q_y, \\n\\td. for epoch in range(NUM_EPOCHS_PER_QUESTION):\\n        \\toptimizer.zero_grad()\\n        \\tout = model(data)\\n        \\tloss = F.nll_loss(out, data.y, weight = torch.tensor([0.000001, 1-0.000001]))\\n        \\tloss.backward()\\n        \\toptimizer.step()\\n    \\t\\tlogger.debug(f\"Total Question: {(q_index + 1)}, Total Epochs: {NUM_EPOCHS_PER_QUESTION * (q_index + 1):3d}, Loss: {loss:.4f}\")'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop\n",
    "'''\n",
    "1. create a basic data object\n",
    "2. for each question+embedding+question_node+answer_node:\n",
    "\ta. get all the masks related to the question. # potentially using a method of the QA dataset class\n",
    "\tb. construct the  q_x = qa_data_builder.get_x(to_concat=q_embedding)  # add question embedding to node features embedding\n",
    "\tc. build the Data object for the question with filtered edge types and edge index, data = Data(x=q_x, y=q_y, \n",
    "\td. for epoch in range(NUM_EPOCHS_PER_QUESTION):\n",
    "        \toptimizer.zero_grad()\n",
    "        \tout = model(data)\n",
    "        \tloss = F.nll_loss(out, data.y, weight = torch.tensor([0.000001, 1-0.000001]))\n",
    "        \tloss.backward()\n",
    "        \toptimizer.step()\n",
    "    \t\tlogger.debug(f\"Total Question: {(q_index + 1)}, Total Epochs: {NUM_EPOCHS_PER_QUESTION * (q_index + 1):3d}, Loss: {loss:.4f}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>concepts</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [question, concepts, answers]\n",
       "Index: []"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data = pd.DataFrame(columns = [\"question\",\"concepts\",\"answers\"])\n",
    "qa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>concepts</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the type of Incentive and Commission M...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/RSA/SCM/Ince...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/RSA/SCM/Solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the type of Incentive and Commission M...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/RBA/BCM/Ince...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/RSA/SCM/Solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a MFS-50-10-30 Operated JV Operations ...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/SSC/BPML/MFS...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/SSC/BPML/Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is a MFS-50-10-30 Operated JV Operations ...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/SSC/BPML/MFS...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/SSC/BPML/Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's an 1EZ - Credit Memo Processing (SPFD-1...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/EARL/SAD/1EZ...</td>\n",
       "      <td>[http://www.signavio.com/opal/SAP/EARL/SAD/Sol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the type of Incentive and Commission M...   \n",
       "1  What is the type of Incentive and Commission M...   \n",
       "2  What is a MFS-50-10-30 Operated JV Operations ...   \n",
       "3  What is a MFS-50-10-30 Operated JV Operations ...   \n",
       "4  What's an 1EZ - Credit Memo Processing (SPFD-1...   \n",
       "\n",
       "                                            concepts  \\\n",
       "0  [http://www.signavio.com/opal/SAP/RSA/SCM/Ince...   \n",
       "1  [http://www.signavio.com/opal/SAP/RBA/BCM/Ince...   \n",
       "2  [http://www.signavio.com/opal/SAP/SSC/BPML/MFS...   \n",
       "3  [http://www.signavio.com/opal/SAP/SSC/BPML/MFS...   \n",
       "4  [http://www.signavio.com/opal/SAP/EARL/SAD/1EZ...   \n",
       "\n",
       "                                             answers  \n",
       "0  [http://www.signavio.com/opal/SAP/RSA/SCM/Solu...  \n",
       "1  [http://www.signavio.com/opal/SAP/RSA/SCM/Solu...  \n",
       "2  [http://www.signavio.com/opal/SAP/SSC/BPML/Pro...  \n",
       "3  [http://www.signavio.com/opal/SAP/SSC/BPML/Pro...  \n",
       "4  [http://www.signavio.com/opal/SAP/EARL/SAD/Sol...  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up a process to read each question from gold standard, get the q_entity, also a_entity in a csv format\n",
    "qa_data = pd.DataFrame(columns = [\"question\",\"concepts\",\"answers\"])\n",
    "with open('data\\source_data\\patterd_id_0_qa.json', 'r', encoding='utf-8') as fin:\n",
    "    for line in fin:\n",
    "        dic = json.loads(line)\n",
    "        qa_data = pd.concat([qa_data,pd.DataFrame([dic])],ignore_index=True)\n",
    "qa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qa_data.to_csv('data\\source_data\\questions_concepts_answers.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_encoder = LLMEncoder(tokenizer, encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-16 13:14:34.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mCreating Data object\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Build data\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "## CREATE DATA\n",
    "logger.info(\"Creating Data object\")\n",
    "\n",
    "qa_data_builder = QAMaskBuilder(\n",
    "    triples_path=TRIPLES_PATH_OLD,\n",
    "    entities_labels_path=ENTITIES_LABELS_PATH_OLD,\n",
    "    properties_labels_path=PROPERTIES_LABELS_PATH_OLD,\n",
    "    embeddings_path=GRAPH_EMBEDDINGS_PATH_OLD,\n",
    "    questions_concepts_answers_path=QUESTIONS_CONCEPTS_ANSWERS_PATH,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[29025, 768], edge_index=[2, 145402], edge_type=[145402])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = qa_data_builder.build_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-16 17:33:08.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mTraining GNN\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (layers): ModuleList(\n",
       "    (0): GCNConv(1536, 16)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): GCNConv(16, 2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN GNN\n",
    "logger.info(\"Training GNN\")\n",
    "model = GCN(\n",
    "    num_node_features=q_data.num_node_features, dim_hidden_layer=16,num_layers=2, num_classes=len(set(q_data.y.tolist()))\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-16 17:33:10.785\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mEpoch: 000, Loss: 0.6973\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Q 0 : What is the type of Incentive and Commission Management (S/4 CLD)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-16 17:34:29.544\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mEpoch: 1000, Loss: 0.2068\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for idx, row in qa_data_builder.question_concepts_answers.iterrows():\n",
    "\n",
    "    q_embedding = roberta_encoder.encode_sentence(row[\"question\"])\n",
    "    q_x = qa_data_builder.get_x(to_concat=q_embedding)\n",
    "    q_edge_mask, q_nodes, q_concept_mask, q_answer_mask, q_answer_and_random_nodes_mask =qa_data_builder.get_concepts_and_masks_for_question(question =row[\"question\"], concept_uri= row[\"concepts\"], answer_uri= row[\"answers\"])\n",
    "    q_edge_index = data.edge_index[:,q_edge_mask]\n",
    "    q_edge_type = data.edge_type[q_edge_mask]\n",
    "    q_training_x_mask = qa_data_builder.get_question_training_mask_for_x()\n",
    "    q_y_labels = qa_data_builder.get_question_y_labels()\n",
    "    q_data = Data(x=q_x,edge_index=q_edge_index,edge_type=q_edge_type,train_mask =q_training_x_mask,y=q_y_labels)\n",
    "    print(f'Training for Q {idx} : {row[\"question\"]}')\n",
    "    for epoch in range(200\n",
    "        optimizer.zero_grad()\n",
    "        out,embedding = model(q_data)\n",
    "        loss = F.nll_loss(out[q_data.train_mask], q_data.y[q_data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch%1000==0:\n",
    "            logger.debug(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}\")\n",
    "    break;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for idx, row in qa_data_builder.question_concepts_answers.iterrows():\n",
    "\n",
    "    q_embedding = roberta_encoder.encode_sentence(row[\"question\"])\n",
    "    q_x = qa_data_builder.get_x(to_concat=q_embedding)\n",
    "    q_edge_mask, q_nodes, q_concept_mask, q_answer_mask, q_answer_and_random_nodes_mask =qa_data_builder.get_concepts_and_masks_for_question(question =row[\"question\"], concept_uri= row[\"concepts\"], answer_uri= row[\"answers\"])\n",
    "    q_edge_index = data.edge_index[:,q_edge_mask]\n",
    "    q_edge_type = data.edge_type[q_edge_mask]\n",
    "    q_training_x_mask = qa_data_builder.get_question_training_mask_for_x()\n",
    "    q_y_labels = qa_data_builder.get_question_y_labels()\n",
    "    q_data = Data(x=q_x,edge_index=q_edge_index,edge_type=q_edge_type,train_mask =q_training_x_mask,y=q_y_labels)\n",
    "    model.eval()\n",
    "    out,_ = model(q_data)\n",
    "    predicted_answer_nodes = torch.where(out.argmax(dim=1))\n",
    "    count_predicted_nodes =len(predicted_answer_nodes[0])\n",
    "    actual_answer_nodes = q_nodes[q_answer_mask].tolist()\n",
    "    if count_predicted_nodes > 0:\n",
    "        message=\"answers predicted\"\n",
    "        predicted_answer_nodes_list = predicted_answer_nodes[0].tolist()\n",
    "        is_predicted_in_actual_answers = bool(set(actual_answer_nodes) & set(predicted_answer_nodes_list))\n",
    "        res.append((idx, actual_answer_nodes, predicted_answer_nodes_list,count_predicted_nodes,is_predicted_in_actual_answers))\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        message=\"NO answers found\"\n",
    "        res.append((idx, actual_answer_nodes, np.nan,np.nan,False))\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_idx</th>\n",
       "      <th>actual_answer_nodes</th>\n",
       "      <th>predicted_answer_nodes</th>\n",
       "      <th>count_predicted_nodes</th>\n",
       "      <th>is_predicted_in_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[22581]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_idx actual_answer_nodes  predicted_answer_nodes  count_predicted_nodes  \\\n",
       "0      0             [22581]                     NaN                    NaN   \n",
       "\n",
       "   is_predicted_in_actual  \n",
       "0                   False  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_res = pd.DataFrame.from_records(res,columns=[\"q_idx\",\"actual_answer_nodes\",\"predicted_answer_nodes\",\"count_predicted_nodes\",\"is_predicted_in_actual\"])\n",
    "eval_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Column1': [1, 2, 3], 'Column2': ['A', 'B', 'C']}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do you evaluate the model\n",
    "q_edge_mask, q_nodes, q_concept_mask, q_answer_mask, q_answer_and_random_nodes_mask\n",
    "q_edge_index\n",
    "q_edge_type\n",
    "q_training_x_mask\n",
    "q_y_labels\n",
    "q_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(set(q_nodes[q_answer_mask].tolist()) & set([22581,22589,22555]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    What is the type of Incentive and Commission M...\n",
       "concepts    [http://www.signavio.com/opal/SAP/RSA/SCM/Ince...\n",
       "answers     [http://www.signavio.com/opal/SAP/RSA/SCM/Solu...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22581])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_nodes[q_answer_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.signavio.com/opal/SAP/RSA/SCM/SolutionCapability'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data_builder.index_to_entity[22581]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(q_training_x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_array = torch.tensor([True, False, True, False, True, False, False, True])\n",
    "\n",
    "passed_node_id = torch.where(boolean_array)[0]\n",
    "passed_node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passed_node_id[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out,_ = model(q_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29025, 2])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28122)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(out.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.signavio.com/opal/SAP/SFSF/AL/Process'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data_builder.index_to_entity[23565]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6187, -0.6076, -0.6111,  ..., -0.6067, -0.6039, -0.6040],\n",
       "       grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.max(dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psmg-imkg-gnn-qa-b42qFiTl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
