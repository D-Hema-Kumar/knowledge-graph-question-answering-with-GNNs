{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from DataBuilder import QADataBuilder\n",
    "from constants import (\n",
    "    TRIPLES_PATH,\n",
    "    ENTITIES_LABELS_PATH,\n",
    "    PROPERTIES_LABELS_PATH,\n",
    "    GRAPH_EMBEDDINGS_PATH,\n",
    "    QUESTIONS_ANSWERS_PATH,\n",
    "    QUESTIONS_EMBEDDINGS_PATH,\n",
    "    NUM_EPOCHS,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from GNN import GCN, MLP, evaluate_qa_model\n",
    "from loguru import logger\n",
    "import sys\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "## CREATE DATA\n",
    "logger.info(\"Creating Data object\")\n",
    "\n",
    "qa_data_builder = QADataBuilder(\n",
    "    triples_path=TRIPLES_PATH,\n",
    "    entities_labels_path=ENTITIES_LABELS_PATH,\n",
    "    properties_labels_path=PROPERTIES_LABELS_PATH,\n",
    "    embeddings_path=GRAPH_EMBEDDINGS_PATH,\n",
    "    questions_answers_path=QUESTIONS_ANSWERS_PATH,\n",
    "    questions_embeddings_path=QUESTIONS_EMBEDDINGS_PATH,\n",
    ")\n",
    "\n",
    "x = qa_data_builder.get_x()\n",
    "train_mask, test_mask, val_mask = qa_data_builder.get_questions_masks()\n",
    "NUM_EPOCHS_PER_QUESTION = int(NUM_EPOCHS / sum(train_mask))\n",
    "\n",
    "## TRAIN MLP\n",
    "logger.info(\"Training MLP\")\n",
    "model = MLP(\n",
    "    num_node_features=(2 * x.shape[1]), dim_hidden_layer=16, num_classes=2\n",
    ")  # we multiply x.shape by two so as to account for question embedding\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()\n",
    "\n",
    "for q_index, question_embedding in enumerate(\n",
    "    qa_data_builder.questions_embeddings_masked(train_mask)\n",
    "):  # call the questions_iterator from the instance\n",
    "    question, q_embedding = question_embedding\n",
    "    q_x = qa_data_builder.get_x(\n",
    "        to_concat=q_embedding\n",
    "    )  # add question embedding to node features embedding\n",
    "    q_y = qa_data_builder.get_y(question=question)\n",
    "    data = Data(x=q_x, y=q_y)\n",
    "    if not data.validate():\n",
    "        logger.error(f\"Data object is not valid for question {question}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS_PER_QUESTION):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y, weight = torch.tensor([0.000001, 1-0.000001]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    logger.debug(\n",
    "        f\"Total Question: {(q_index + 1)}, Total Epochs: {NUM_EPOCHS_PER_QUESTION * (q_index + 1):3d}, Loss: {loss:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_qa_model(model=model, qa_data_builder=qa_data_builder, mask=train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_answer(model, data):\n",
    "    \"\"\"\n",
    "    Returns the predicted answer and node index.\n",
    "    \"\"\"\n",
    "    return model(data).max(dim=1)[0].argmax().item()\n",
    "\n",
    "def evaluate_qa_model(model, qa_data_builder, mask):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    for q_index, question_embedding in enumerate(\n",
    "        qa_data_builder.questions_embeddings_masked(mask)\n",
    "    ):\n",
    "        question, q_embedding = question_embedding\n",
    "        x_q = qa_data_builder.get_x(\n",
    "            to_concat=q_embedding\n",
    "        )  # adding the question embedding to the node embeddings\n",
    "        y_q = qa_data_builder.get_y(question=question)\n",
    "        data = Data(x=x_q, edge_index=qa_data_builder.get_edge_index(), y=y_q)\n",
    "        pred_node_idx = _predict_answer(model, data)\n",
    "        actual_node_idx = qa_data_builder.get_node_index_for_question_answer(question)\n",
    "        if pred_node_idx == actual_node_idx:\n",
    "            logger.debug(f\"Correctly predicted answer to question {question}.\")\n",
    "            correct_predictions += 1\n",
    "        elif pred_node_idx != torch.tensor(0):\n",
    "            logger.debug(\n",
    "                f\"Question: {question}. Predicted answer = {qa_data_builder.index_to_entity[pred_node_idx]}, Actual answer: {qa_data_builder.index_to_entity[actual_node_idx]}\"\n",
    "            )\n",
    "        else:\n",
    "            logger.debug(f\"Could not predict any answer\")\n",
    "    return correct_predictions / (q_index + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array([1,2,3]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psmg-imkg-gnn-qa-b42qFiTl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
